{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQUIjHDbLarx"
      },
      "source": [
        "# Configuração do Ambiente para YOLO v11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rnFdxiehLarx"
      },
      "outputs": [],
      "source": [
        "# Instalar Ultralytics (YOLO v11)\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjUug9KvLarx"
      },
      "outputs": [],
      "source": [
        "# Verificar a versão do YOLO instalada\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRikFoPOLary"
      },
      "outputs": [],
      "source": [
        "# Verificar a disponibilidade da GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wAZ8gCkLary"
      },
      "source": [
        "# Preparação dos Dados para YOLO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: add a code to extract /content/individual_urban_tree_crown_detection.zip to a folder of the same name\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file_path = '/content/individual_urban_tree_crown_detection.zip'\n",
        "extract_folder_name = 'individual_urban_tree_crown_detection'\n",
        "extract_path = os.path.join('/content', extract_folder_name)\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(extract_path):\n",
        "    os.makedirs(extract_path)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Extracted {zip_file_path} to {extract_path}\")"
      ],
      "metadata": {
        "id": "5gbmPQk0KGK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4FCEaW9Lary"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "# --- CONFIGURE AQUI ---\n",
        "# Caminho base do dataset descompactado (assumindo que já foi descompactado para /home/ubuntu/dataset/individual_urban_tree_crown_detection)\n",
        "base_dataset_path = \"/content/individual_urban_tree_crown_detection/individual_urban_tree_crown_detection\"\n",
        "\n",
        "# 1. Caminho para a pasta com os patches de imagem RGB\n",
        "source_images_dir = os.path.join(base_dataset_path, \"rgb\")\n",
        "# 2. Caminho para a pasta com as anotações (.txt) em formato de PIXELS\n",
        "source_labels_dir = os.path.join(base_dataset_path, \"bbox_txt\")\n",
        "# 3. Caminho para a pasta com as listas de arquivos (contendo as pastas 0, 1, 2, 3, 4)\n",
        "split_files_dir = os.path.join(base_dataset_path, \"img_list\")\n",
        "# 4. Escolha qual 'fold' (pasta de 0 a 4) usar para a divisão\n",
        "fold_to_use = 0  # Mude para 1, 2, 3, ou 4 para usar outros folds\n",
        "# 5. Extensão dos seus arquivos de imagem (ex: '.jpg', '.png')\n",
        "image_extension = '.png'\n",
        "# ---------------------\n",
        "\n",
        "# Nome da pasta base para o dataset formatado para o YOLO\n",
        "base_dir = \"/content/yolo_dataset\"\n",
        "\n",
        "# Limpa e cria a estrutura de pastas do zero\n",
        "if os.path.exists(base_dir):\n",
        "    shutil.rmtree(base_dir)\n",
        "os.makedirs(os.path.join(base_dir, 'images/train'), exist_ok=True)\n",
        "os.makedirs(os.path.join(base_dir, 'images/val'), exist_ok=True)\n",
        "os.makedirs(os.path.join(base_dir, 'labels/train'), exist_ok=True)\n",
        "os.makedirs(os.path.join(base_dir, 'labels/val'), exist_ok=True)\n",
        "print(f\"Estrutura de pastas criada em: {base_dir}\")\n",
        "\n",
        "def get_filenames_from_list(filepath):\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"ERRO: Arquivo de lista não encontrado em: {filepath}\")\n",
        "        return []\n",
        "    with open(filepath, 'r') as f:\n",
        "        return [line.strip() for line in f.readlines() if line.strip()]\n",
        "\n",
        "train_list_path = os.path.join(split_files_dir, str(fold_to_use), 'train.txt')\n",
        "val_list_path = os.path.join(split_files_dir, str(fold_to_use), 'val.txt')\n",
        "train_basenames = get_filenames_from_list(train_list_path)\n",
        "val_basenames = get_filenames_from_list(val_list_path)\n",
        "\n",
        "print(f\"\\nUsando Fold: {fold_to_use}\")\n",
        "print(f\"Imagens de treino a serem processadas: {len(train_basenames)}\")\n",
        "print(f\"Imagens de validação a serem processadas: {len(val_basenames)}\")\n",
        "\n",
        "def process_and_copy_files(basename_list, source_img_dir, source_lbl_dir, dest_img_dir, dest_lbl_dir, img_ext):\n",
        "    \"\"\"\n",
        "    Copia as imagens e processa os arquivos de anotação para o formato YOLO.\n",
        "    Assume que o formato de origem é: x_min y_min x_max y_max (por linha)\n",
        "    Converte para: class_id center_x_norm center_y_norm width_norm height_norm\n",
        "    \"\"\"\n",
        "    processed_count = 0\n",
        "    for base_filename in basename_list:\n",
        "        img_filename = base_filename\n",
        "        # O nome do arquivo de label é o mesmo do arquivo de imagem, mas com extensão .txt\n",
        "        label_filename = f\"{os.path.splitext(base_filename)[0]}.txt\"\n",
        "\n",
        "        source_img_path = os.path.join(source_img_dir, img_filename)\n",
        "        source_label_path = os.path.join(source_lbl_dir, label_filename)\n",
        "        dest_img_path = os.path.join(dest_img_dir, img_filename)\n",
        "        dest_label_path = os.path.join(dest_lbl_dir, label_filename)\n",
        "\n",
        "        if os.path.exists(source_img_path) and os.path.exists(source_label_path):\n",
        "            # Obter as dimensões da imagem\n",
        "            try:\n",
        "                with Image.open(source_img_path) as img:\n",
        "                    IMG_WIDTH, IMG_HEIGHT = img.size\n",
        "            except Exception as e:\n",
        "                print(f\"ERRO ao ler imagem {source_img_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "            # 1. Copia o arquivo de imagem\n",
        "            shutil.copy(source_img_path, dest_img_path)\n",
        "\n",
        "            # 2. Converte o arquivo de anotação\n",
        "            normalized_labels = []\n",
        "            with open(source_label_path, 'r') as f_in:\n",
        "                for line in f_in:\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) < 4: continue # Ignora linhas mal formatadas\n",
        "\n",
        "                    # Assume o formato x_min, y_min, x_max, y_max\n",
        "                    x_min, y_min, x_max, y_max = map(float, parts[:4])\n",
        "\n",
        "                    # Calcula o centro, largura e altura em pixels\n",
        "                    box_width = x_max - x_min\n",
        "                    box_height = y_max - y_min\n",
        "                    center_x = x_min + (box_width / 2)\n",
        "                    center_y = y_min + (box_height / 2)\n",
        "\n",
        "                    # Normaliza as coordenadas\n",
        "                    norm_center_x = center_x / IMG_WIDTH\n",
        "                    norm_center_y = center_y / IMG_HEIGHT\n",
        "                    norm_width = box_width / IMG_WIDTH\n",
        "                    norm_height = box_height / IMG_HEIGHT\n",
        "\n",
        "                    # Adiciona o ID da classe (0 para 'tree')\n",
        "                    # Formato: class_id center_x center_y width height\n",
        "                    normalized_labels.append(f\"0 {norm_center_x:.6f} {norm_center_y:.6f} {norm_width:.6f} {norm_height:.6f}\")\n",
        "\n",
        "            # Salva o novo arquivo de anotação normalizado\n",
        "            with open(dest_label_path, 'w') as f_out:\n",
        "                f_out.write(\"\\n\".join(normalized_labels))\n",
        "\n",
        "            processed_count += 1\n",
        "        else:\n",
        "            if not os.path.exists(source_img_path):\n",
        "                print(f\"AVISO: Imagem '{img_filename}' não encontrada em {source_img_dir}.\")\n",
        "            if not os.path.exists(source_label_path):\n",
        "                print(f\"AVISO: Anotação '{label_filename}' não encontrada em {source_labels_dir}.\")\n",
        "            print(f\"--> O par para '{base_filename}' será ignorado.\")\n",
        "\n",
        "    return processed_count\n",
        "\n",
        "# Processa e copia os arquivos de treino\n",
        "print(\"\\nProcessando arquivos de TREINO...\")\n",
        "train_copied = process_and_copy_files(train_basenames, source_images_dir, source_labels_dir, os.path.join(base_dir, 'images/train'), os.path.join(base_dir, 'labels/train'), image_extension)\n",
        "print(f\"{train_copied} pares de imagem/anotação processados para o conjunto de treino.\")\n",
        "\n",
        "# Processa e copia os arquivos de validação\n",
        "print(\"\\nProcessando arquivos de VALIDAÇÃO...\")\n",
        "val_copied = process_and_copy_files(val_basenames, source_images_dir, source_labels_dir, os.path.join(base_dir, 'images/val'), os.path.join(base_dir, 'labels/val'), image_extension)\n",
        "print(f\"{val_copied} pares de imagem/anotação processados para o conjunto de validação.\")\n",
        "\n",
        "# Verificação final\n",
        "print(\"\\n--- Verificação Final ---\")\n",
        "train_img_count = len(os.listdir(os.path.join(base_dir, 'images/train')))\n",
        "train_lbl_count = len(os.listdir(os.path.join(base_dir, 'labels/train')))\n",
        "val_img_count = len(os.listdir(os.path.join(base_dir, 'images/val')))\n",
        "val_lbl_count = len(os.listdir(os.path.join(base_dir, 'labels/val')))\n",
        "print(f\"Imagens de treino: {train_img_count} | Anotações de treino: {train_lbl_count}\")\n",
        "print(f\"Imagens de validação: {val_img_count} | Anotações de validação: {val_lbl_count}\")\n",
        "\n",
        "if train_img_count == train_lbl_count and val_img_count == val_lbl_count and train_img_count > 0 and val_img_count > 0:\n",
        "    print(\"\\nOrganização e normalização do dataset concluídas com sucesso!\")\n",
        "else:\n",
        "    print(\"\\nERRO: A contagem de imagens e anotações não corresponde. Verifique os avisos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9m_vq4NLary"
      },
      "source": [
        "# Configuração do Arquivo YAML do Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0o_vq4NLary"
      },
      "outputs": [],
      "source": [
        "# Criar o arquivo data.yaml para o YOLO\n",
        "yaml_content = f\"\"\"\\\n",
        "path: {base_dir}  # Caminho para a pasta raiz do dataset\n",
        "train: images/train  # Caminho relativo para as imagens de treino\n",
        "val: images/val    # Caminho relativo para as imagens de validação\n",
        "\n",
        "# Número de classes\n",
        "nc: 1\n",
        "\n",
        "# Nomes das classes\n",
        "names: ['tree']\n",
        "\"\"\"\n",
        "with open(os.path.join(base_dir, \"data.yaml\"), \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"Arquivo data.yaml criado com sucesso:\")\n",
        "print(yaml_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1p_vq4NLary"
      },
      "source": [
        "# Treinamento do Modelo YOLOv11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2q_vq4NLary"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Carregar um modelo pré-treinado (ex: yolov8n.pt para YOLOv8 nano, ou yolov11.pt se disponível)\n",
        "# Para YOLOv11, você pode precisar baixar o modelo correspondente ou usar um modelo YOLOv8 como base\n",
        "# Se yolov11.pt não estiver disponível, tente yolov8n.pt ou outro modelo YOLOv8\n",
        "model = YOLO('yolo11s.pt')  # Substitua por 'yolov11.pt' se tiver o modelo\n",
        "\n",
        "# Treinar o modelo\n",
        "results = model.train(data=os.path.join(base_dir, \"data.yaml\"), epochs=40, imgsz=512, batch=16)\n",
        "\n",
        "print(\"Treinamento concluído! Resultados salvos em runs/detect/train\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TWdT6EI1MC5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: gere um codigo para copiar a pasta /content/runs para o MeuDrive, porém se a pasta já existir, ele cria outra igual com numeração, ex: testes1, testes2, etc.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "source_dir = '/content/runs'\n",
        "destination_base_dir = '/content/drive/MyDrive/yolov11' # Base path in Google Drive\n",
        "\n",
        "# Ensure the base destination directory exists\n",
        "if not os.path.exists(destination_base_dir):\n",
        "    os.makedirs(destination_base_dir)\n",
        "\n",
        "# Check if the source directory exists\n",
        "if not os.path.exists(source_dir):\n",
        "    print(f\"Source directory does not exist: {source_dir}\")\n",
        "else:\n",
        "    # Determine the destination path, checking for existing folders\n",
        "    dest_dir = os.path.join(destination_base_dir, 'runs')\n",
        "    counter = 1\n",
        "    while os.path.exists(dest_dir):\n",
        "        dest_dir = os.path.join(destination_base_dir, f'runs_{counter}')\n",
        "        counter += 1\n",
        "\n",
        "    # Copy the directory\n",
        "    try:\n",
        "        shutil.copytree(source_dir, dest_dir)\n",
        "        print(f\"Successfully copied '{source_dir}' to '{dest_dir}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error copying directory: {e}\")"
      ],
      "metadata": {
        "id": "Rk4f-Kj6MKY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3r_vq4NLary"
      },
      "source": [
        "# Validação do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4s_vq4NLary"
      },
      "outputs": [],
      "source": [
        "# Validar o modelo treinado\n",
        "metrics = model.val()  # Valida o modelo nos dados de validação definidos em data.yaml\n",
        "\n",
        "print(\"Métricas de validação:\")\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5t_vq4NLary"
      },
      "source": [
        "# Inferência (Detecção em Novas Imagens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6u_vq4NLary"
      },
      "outputs": [],
      "source": [
        "# Realizar inferência em uma imagem de teste (exemplo)\n",
        "# Substitua 'path/to/your/test_image.png' pelo caminho de uma imagem que você queira testar\n",
        "# Certifique-se de que a imagem esteja acessível no ambiente\n",
        "test_image_path = os.path.join(base_dir, 'images/val/132.png') # Exemplo: usando uma imagem do conjunto de validação\n",
        "\n",
        "if os.path.exists(test_image_path):\n",
        "    results = model(test_image_path)  # Executa a inferência\n",
        "\n",
        "    # Mostrar os resultados (opcional)\n",
        "    for r in results:\n",
        "        im_bgr = r.plot()  # plotagem BGR da imagem com caixas e rótulos\n",
        "        # Para exibir no Jupyter/Colab, você pode converter para RGB e usar matplotlib\n",
        "        import cv2\n",
        "        import matplotlib.pyplot as plt\n",
        "        im_rgb = cv2.cvtColor(im_bgr, cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(im_rgb)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "else:\n",
        "    print(f\"Imagem de teste não encontrada: {test_image_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}